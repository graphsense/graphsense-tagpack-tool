#!/usr/bin/env python
import glob
import json
import os
import sys
import time
from argparse import ArgumentParser

import pandas as pd
import yaml
from tabulate import tabulate

from tagpack import __version__ as version
from tagpack.cmd_utils import print_line, print_info, print_fail, print_success
from tagpack.graphsense import GraphSense
from tagpack.tagpack import TagPack, TagPackFileError
from tagpack.tagpack_schema import TagPackSchema, ValidationError
from tagpack.tagstore import TagStore
from tagpack.taxonomy import Taxonomy

CONFIG_FILE = "config.yaml"

TAXONOMY_URL = 'https://graphsense.github.io'

DEFAULT_CONFIG = {
    'baseURI': 'uri:test',
    'taxonomies': {
        'entity': f'{TAXONOMY_URL}/DW-VA-Taxonomy/assets/data/entities.csv',
        'abuse': f'{TAXONOMY_URL}/DW-VA-Taxonomy/assets/data/abuses.csv'
    }
}


_DEFAULT_SCHEMA = "tagstore"


def remote_load_taxonomies():
    if 'taxonomies' not in CONFIG:
        return None
    taxonomies = {}
    for key in CONFIG['taxonomies']:
        taxonomy = remote_load_taxonomy(key)
        taxonomies[key] = taxonomy
    return taxonomies


def remote_load_taxonomy(key):
    if 'taxonomies' not in CONFIG:
        return None
    uri = CONFIG['taxonomies'][key]
    taxonomy = Taxonomy(key, uri)
    taxonomy.load_from_remote()
    return taxonomy


def list_taxonomies(args=None):
    print_line("Show configured taxonomies")
    print_line(f"Configuration: {CONFIG_FILE}", 'info')
    count = 0
    if 'taxonomies' not in CONFIG:
        print_line("No configured taxonomies", 'fail')
    else:
        for key, value in CONFIG['taxonomies'].items():
            print_line(value)
            count += 1
        print_line(f"{count} configured taxonomies", 'success')


def show_taxonomy_concepts(args):
    if 'taxonomies' not in CONFIG:
        print_line("No taxonomies configured", 'fail')
        return
    print_line("Showing concepts of taxonomy {}".format(args.taxonomy))
    print("Remote URI: ", CONFIG['taxonomies'][args.taxonomy], "\n")
    taxonomy = remote_load_taxonomy(args.taxonomy)
    if args.verbose:
        headers = ['Id', 'Label', 'Uri', 'Description']
        table = [[c.id, c.label, c.uri, c.description]
                 for c in taxonomy.concepts]
    else:
        headers = ['Id', 'Label']
        table = [[c.id, c.label] for c in taxonomy.concepts]

    print(tabulate(table, headers=headers))
    print_line(f"{len(taxonomy.concepts)} taxonomy concepts", 'success')


def insert_taxonomy(args):
    if 'taxonomies' not in CONFIG:
        print_line("No taxonomies configured", 'fail')
        return
    t0 = time.time()
    print_line("Taxonomy insert starts")
    print(f"Taxonomy: {args.taxonomy}")

    tagstore = TagStore(args.url, args.schema)
    try:
        taxonomy = remote_load_taxonomy(args.taxonomy)
        tagstore.insert_taxonomy(taxonomy)

        print(f"{taxonomy.key} | {taxonomy.uri}:", end=' ')
        print_success("INSERTED")

        duration = round(time.time() - t0, 2)
        print_line(
            f"Inserted {len(taxonomy.concepts)} concepts in {duration}s",
            'success')
    except Exception as e:
        print_fail(e)
        print_line("Aborted insert", 'fail')


def load_config():
    if not os.path.isfile(CONFIG_FILE):
        print_line(
            "Could not find TagPack repository configuration file.", 'fail')
        new = input("Create a new default configuration? (y/n) ")
        if new == 'y':
            with open('config.yaml', 'a') as the_file:
                yaml.dump(DEFAULT_CONFIG, the_file, allow_unicode=True)
        else:
            sys.exit("This program requires a repository config file in {}"
                     .format(os.getcwd()))
    return yaml.safe_load(open(CONFIG_FILE, 'r'))


def show_config(args):
    print("Config File:", os.path.abspath(CONFIG_FILE))
    if args.verbose:
        print("BaseURI:", CONFIG['baseURI'])
        list_taxonomies()


def collect_tagpack_files(paths):
    """Collect Tagpack YAML files from given paths"""
    tagpack_files = []
    for path in paths:
        if os.path.isdir(path):
            files = glob.glob(path + '/**/*.yaml', recursive=True)
            tagpack_files = tagpack_files + files
        elif os.path.isfile(path):
            tagpack_files.append(path)
    return tagpack_files


def validate_tagpack(args):
    t0 = time.time()
    print_line("TagPack validation starts")
    print(f"Path: {args.path}")

    taxonomies = remote_load_taxonomies()
    taxonomy_keys = [key for key in taxonomies.keys()]
    print(f"Loaded taxonomies: {taxonomy_keys}")

    schema = TagPackSchema()
    print(f"Loaded schema: {schema.definition}")

    tagpack_files = collect_tagpack_files(args.path)
    print_info(f"Collected {len(tagpack_files)} TagPack files\n")

    no_passed = 0
    try:
        for tagpack_file in tagpack_files:
            tagpack = TagPack.load_from_file(CONFIG['baseURI'], tagpack_file,
                                             schema, taxonomies)

            print(f'{tagpack_file}: ', end='')

            tagpack.validate()
            print_success("PASSED")
            no_passed += 1
    except (ValidationError, TagPackFileError) as e:
        print_fail("FAILED", e)

    status = 'fail' if no_passed < len(tagpack_files) else 'success'

    duration = round(time.time() - t0, 2)
    print_line("{}/{} TagPacks passed in {}s"
               .format(no_passed, len(tagpack_files), duration), status)


def insert_tagpack(args):
    t0 = time.time()
    print_line("TagPack insert starts")
    print(f"Path: {args.path}")

    tagstore = TagStore(args.url, args.schema)

    schema = TagPackSchema()
    print_info(f"Loaded TagPack schema definition: {schema.definition}")

    taxonomies = remote_load_taxonomies()
    taxonomy_keys = [key for key in taxonomies.keys()]
    print(f"Loaded taxonomies: {taxonomy_keys}")

    tagpack_files = collect_tagpack_files(args.path)
    print_info(f"Collected {len(tagpack_files)} TagPack files\n")

    no_passed = 0
    no_tags = 0
    for tagpack_file in tagpack_files:
        tagpack = TagPack.load_from_file(CONFIG['baseURI'], tagpack_file,
                                         schema, taxonomies)

        print(f'{tagpack_file}: ', end='')
        try:
            tagstore.insert_tagpack(tagpack, args.public)
            print_success(f"PROCESSED {len(tagpack.tags)} Tags")
            no_passed += 1
            no_tags = no_tags + len(tagpack.tags)
        except Exception as e:
            print_fail("FAILED", e)

    status = 'fail' if no_passed < len(tagpack_files) else 'success'

    duration = round(time.time() - t0, 2)
    print_line("Processed {}/{} TagPacks with {} Tags in {}s. Only tags for supported currencies {} are inserted."
               .format(no_passed, len(tagpack_files), no_tags, duration, tagstore.supported_currencies),
               status)


def split_into_chunks(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


def insert_cluster_mapping(args, batch_size=5_000):
    tagstore = TagStore(args.url, args.schema)
    df = pd.DataFrame(tagstore.get_addresses(args.update), columns=['address', 'currency'])

    ks_mapping = json.load(open(args.ks_file))
    gs = GraphSense(args.db_nodes, ks_mapping)

    processed_currencies = []
    t0 = time.time()
    for currency, data in df.groupby('currency'):
        if gs.contains_keyspace_mapping(currency):
            try:
                print(currency)
                mappings_count = 0
                for batch in split_into_chunks(data, batch_size):
                    clusters = gs.get_address_clusters(batch, currency)
                    clusters['currency'] = currency
                    tagstore.insert_cluster_mappings(clusters)
                    mappings_count += len(clusters)

                print_success(f"INSERTED/UPDATED {mappings_count} {currency} cluster mappings")
                processed_currencies.append(currency)
            except Exception as e:
                print_fail("FAILED", e)

    duration = round(time.time() - t0, 2)
    print_line(f"Inserted {'missing' if not args.update else 'all'} cluster mappings for {processed_currencies} in {duration}s", "success")
    tagstore.finish_mappings_update(gs.ks_map.keys())


def update_db(args):
    tagstore = TagStore(args.url, args.schema)
    tagstore.refresh_db()


def show_version():
    return "GraphSense TagPack management tool v" + version


def main():
    parser = ArgumentParser(
        description='GraphSense TagPack validation and ingest tool',
        epilog='GraphSense TagPack Tool v{} - https://graphsense.info'
        .format(version))
    parser.add_argument('-v', '--version', action='version',
                        version=show_version())

    subparsers = parser.add_subparsers(title='Commands')

    # parser for taxonomy command
    parser_t = subparsers.add_parser("taxonomy",
                                     help="show taxonomy concepts")
    parser_t.set_defaults(func=list_taxonomies)

    parser_t_subparsers = parser_t.add_subparsers(title='Taxonomy commands')

    # parser for taxonomy insert command
    parser_t_i = parser_t_subparsers.add_parser(
        'insert', help='insert taxonomy into GraphSense')
    parser_t_i.add_argument('taxonomy', metavar='TAXONOMY_KEY',
                            help='the selected taxonomy')
    parser_t_i.add_argument('--schema',
                            default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                            help="PostgreSQL schema for taxonomy tables")
    parser_t_i.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_t_i.set_defaults(func=insert_taxonomy)

    # parser for taxonomy show command
    parser_t_s = parser_t_subparsers.add_parser(
        'show', help='show taxonomy concepts')
    parser_t_s.add_argument('taxonomy', metavar='TAXONOMY_KEY',
                            help='the selected taxonomy')
    parser_t_s.add_argument('-v', '--verbose', action='store_true',
                            help="verbose concepts")
    parser_t_s.set_defaults(func=show_taxonomy_concepts)

    # parser for config command
    parser_c = subparsers.add_parser("config",
                                     help="show TagPack Repository config")
    parser_c.add_argument('-v', '--verbose', action='store_true',
                          help='verbose configuration')
    parser_c.set_defaults(func=show_config)

    # parser for insert command
    parser_i = subparsers.add_parser("insert",
                                     help="insert TagPacks into GraphSense")
    parser_i.add_argument('path', nargs='+', metavar='PATH',
                          default=[os.getcwd()],
                          help='TagPacks file or folder root path')
    parser_i.add_argument('--schema',
                          default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                          help="PostgreSQL schema for tagpack tables")
    parser_i.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_i.add_argument('-b', '--batch_size', nargs='?', type=int,
                          default=1000,
                          help='batch size for insert)')
    parser_i.add_argument("--public", action='store_true',
                        help='By default, tagpacks are declared private in the database. '
                             'Use this switch to declare them public.')
    parser_i.set_defaults(func=insert_tagpack)

    # parser for validate command
    parser_v = subparsers.add_parser("validate", help="validate TagPacks")
    parser_v.add_argument('path', nargs='+', metavar='PATH',
                          default=[os.getcwd()],
                          help='TagPacks file or folder root path')
    parser_v.set_defaults(func=validate_tagpack)

    # parser for cluster command
    parser_cl = subparsers.add_parser("cluster",
                                     help="insert cluster mappings")
    parser_cl.add_argument('-d', '--db_nodes', nargs='+',
                          default=['localhost'], metavar='DB_NODE',
                          help='Cassandra node(s); default "localhost")')
    parser_cl.add_argument('-f', '--ks_file',
                          metavar='KEYSPACE_FILE',
                          help="JSON file with Cassandra keyspaces that contain GraphSense cluster mappings")
    parser_cl.add_argument('--schema',
                          default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                          help="PostgreSQL schema for GraphSense cluster mapping table")
    parser_cl.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_cl.add_argument('--update', help='update  all cluster mappings', action='store_true')
    parser_cl.set_defaults(update=False)
    parser_cl.set_defaults(func=insert_cluster_mapping)

    # parser for database statistics refresh
    parser_db = subparsers.add_parser("db",
                            help="refresh database statistics")
    parser_db.add_argument('--schema',
                           default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                           help="PostgreSQL schema for GraphSense cluster mapping table")
    parser_db.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_db.set_defaults(func=update_db)

    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)

    args = parser.parse_args()
    args.func(args)


if __name__ == '__main__':
    if sys.version_info < (3, 6):
        sys.exit("This program requires python version 3.6 or later")

    global CONFIG
    CONFIG = load_config()
    main()
